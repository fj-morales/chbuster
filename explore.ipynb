{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib.pyplot import hist\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_as_number(df_column):\n",
    "    if df_column.dtype == 'O':\n",
    "        df_column = df_column.str.replace(',','')\n",
    "        df_column = df_column.str.replace('K','e3')\n",
    "        df_column = df_column.str.replace('M','e6')\n",
    "        df_column = df_column.str.replace('G','e9')\n",
    "        return df_column.astype(float)        \n",
    "    else:\n",
    "        return df_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dtypes(df):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df['Likes'] = read_as_number(df['Likes'])\n",
    "    df['Popularity'] = read_as_number(df['Popularity'])\n",
    "    df['Time_epoch'] = df['Timestamp'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(df, col_list):\n",
    "    for col in col_list:\n",
    "        if 'genre_' + col not in df.columns:\n",
    "            df[col] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_econde(df):\n",
    "    return pd.concat([df, pd.get_dummies(df['Genre'], prefix='genre')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(y, train_stats):\n",
    "    x = y.copy()\n",
    "    cols = ['Likes', 'Comments', 'Popularity', 'Followers']\n",
    "    for col in cols:\n",
    "        x_col = (x.loc[:, col].copy() - train_stats.loc[col, 'mean']) / train_stats.loc[col, 'std']\n",
    "        x.drop(columns=[col], inplace=True)\n",
    "        x[col] = pd.DataFrame(x_col, columns=[col])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "\n",
    "def build_model(feature_names):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[len(feature_names)]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './data/Data_Train.csv'\n",
    "test_file = './data/Data_Test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from CSV\n",
    "# and convert NaN to string\n",
    "\n",
    "train_orig = pd.read_csv(train_file, na_filter=False) \n",
    "test = pd.read_csv(test_file, na_filter=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data types\n",
    "\n",
    "train_orig = normalize_dtypes(train_orig)\n",
    "test = normalize_dtypes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outlier Views\n",
    "\n",
    "outliers_msk = train_orig['Views'] > 1e6\n",
    "train_wo_outliers = train_orig[~outliers_msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unique_ID</th>\n",
       "      <td>19615.0</td>\n",
       "      <td>7.487063e+05</td>\n",
       "      <td>4.814971e+05</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>3.224025e+05</td>\n",
       "      <td>6.620160e+05</td>\n",
       "      <td>1.189599e+06</td>\n",
       "      <td>1.570002e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comments</th>\n",
       "      <td>19615.0</td>\n",
       "      <td>1.188540e+02</td>\n",
       "      <td>8.721160e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>8.712800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Likes</th>\n",
       "      <td>19615.0</td>\n",
       "      <td>8.962272e+03</td>\n",
       "      <td>5.197153e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.360000e+02</td>\n",
       "      <td>6.690000e+02</td>\n",
       "      <td>2.826000e+03</td>\n",
       "      <td>2.150000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity</th>\n",
       "      <td>19615.0</td>\n",
       "      <td>9.590376e+02</td>\n",
       "      <td>5.044125e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>8.800000e+01</td>\n",
       "      <td>4.000000e+02</td>\n",
       "      <td>1.860000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Followers</th>\n",
       "      <td>19615.0</td>\n",
       "      <td>4.833045e+05</td>\n",
       "      <td>1.169496e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.778400e+04</td>\n",
       "      <td>9.070400e+04</td>\n",
       "      <td>3.936550e+05</td>\n",
       "      <td>9.789123e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time_epoch</th>\n",
       "      <td>19615.0</td>\n",
       "      <td>1.464741e+18</td>\n",
       "      <td>8.938279e+16</td>\n",
       "      <td>9.469440e+16</td>\n",
       "      <td>1.429663e+18</td>\n",
       "      <td>1.484265e+18</td>\n",
       "      <td>1.524871e+18</td>\n",
       "      <td>1.551061e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count          mean           std           min           25%  \\\n",
       "Unique_ID   19615.0  7.487063e+05  4.814971e+05  8.000000e+00  3.224025e+05   \n",
       "Comments    19615.0  1.188540e+02  8.721160e+02  0.000000e+00  1.000000e+00   \n",
       "Likes       19615.0  8.962272e+03  5.197153e+04  0.000000e+00  1.360000e+02   \n",
       "Popularity  19615.0  9.590376e+02  5.044125e+03  0.000000e+00  1.400000e+01   \n",
       "Followers   19615.0  4.833045e+05  1.169496e+06  1.000000e+00  1.778400e+04   \n",
       "Time_epoch  19615.0  1.464741e+18  8.938279e+16  9.469440e+16  1.429663e+18   \n",
       "\n",
       "                     50%           75%           max  \n",
       "Unique_ID   6.620160e+05  1.189599e+06  1.570002e+06  \n",
       "Comments    1.200000e+01  6.000000e+01  8.712800e+04  \n",
       "Likes       6.690000e+02  2.826000e+03  2.150000e+06  \n",
       "Popularity  8.800000e+01  4.000000e+02  1.860000e+05  \n",
       "Followers   9.070400e+04  3.936550e+05  9.789123e+06  \n",
       "Time_epoch  1.484265e+18  1.524871e+18  1.551061e+18  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get statistics\n",
    "\n",
    "train_stats = train_wo_outliers.describe()\n",
    "train_stats.pop('Views')\n",
    "train_stats = train_stats.transpose()\n",
    "\n",
    "test_stats = test.describe()\n",
    "test_stats = test_stats.transpose()\n",
    "test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding \n",
    "\n",
    "unique_genres = pd.concat([train_wo_outliers['Genre'], test['Genre']], sort=False).unique()\n",
    "\n",
    "train_wo_outliers = one_hot_econde(train_wo_outliers)\n",
    "train_wo_outliers = add_columns(train_wo_outliers, unique_genres)\n",
    "\n",
    "test = one_hot_econde(test)\n",
    "test = add_columns(test, unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split training train and validation\n",
    "\n",
    "# train_msk = np.random.rand(len(train_wo_outliers)) < 0.75\n",
    "# train = train_wo_outliers[train_msk]\n",
    "train = train_wo_outliers\n",
    "# val = train_wo_outliers[~train_msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "\n",
    "norm_train = normalize(train, train_stats)\n",
    "# norm_val = normalize(val, train_stats)\n",
    "norm_test = normalize(test, train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels\n",
    "\n",
    "train_labels = norm_train.pop('Views')\n",
    "# val_labels = norm_val.pop('Views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape neural networks\n",
    "\n",
    "feature_names = list(norm_train.columns.values)[7:]\n",
    "feature_names \n",
    "# norm_train[feature_names]\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "model = build_model(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1664      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,889\n",
      "Trainable params: 5,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0104 22:19:30.658853 139952386103040 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.16944888],\n",
       "       [-0.163258  ],\n",
       "       [-0.16359307],\n",
       "       [ 0.10437435],\n",
       "       [-0.08274501],\n",
       "       [ 0.05082845],\n",
       "       [-0.1600997 ],\n",
       "       [ 0.38741535],\n",
       "       [-0.0974264 ],\n",
       "       [-0.06971568]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying the model out\n",
    "example_batch = norm_train[feature_names][:10]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0104 22:20:26.893602 139952386103040 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, loss:31685050718.2821,  mae:82692.9453,  mse:31685064704.0000,  val_loss:27267054674.6588,  val_mae:73904.4219,  val_mse:27267072000.0000,  \n",
      ".........................................................................................\n",
      "Epoch: 100, loss:3628802751.3015,  mae:25584.5801,  mse:3628801280.0000,  val_loss:3525323119.7334,  val_mae:25740.3926,  val_mse:3525323264.0000,  \n",
      "........................."
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "norm_features_train = norm_train[feature_names]\n",
    "# norm_features_val = norm_val[feature_names]\n",
    "norm_features_test = norm_test[feature_names]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "  norm_features_train, train_labels,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[tfdocs.modeling.EpochDots()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[~train.Song_Name.isna()])\n",
    "len(train[train.Song_Name.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist(column='Views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(hist_kws={'alpha':.6}, kde_kws={'linewidth':2})\n",
    "plt.figure(figsize=(10,7), dpi= 80)\n",
    "# sns.distplot(train.Views, color=\"dodgerblue\", label=\"Compact\", **kwargs, norm_hist=False, kde=False)\n",
    "sns.distplot(train.Views, color=\"dodgerblue\", label=\"Compact\", **kwargs)\n",
    "sns.distplot(train.Popularity, color=\"orange\", label=\"SUV\", **kwargs)\n",
    "# plt.xlim(50,75)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(hist_kws={'alpha':.6}, kde_kws={'linewidth':2})\n",
    "plt.figure(figsize=(10,7), dpi= 80)\n",
    "sns.distplot(train.Popularity, color=\"dodgerblue\", label=\"Compact\", **kwargs)\n",
    "# plt.xlim(50,75)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax1.hist(train_wo_outliers.Views)\n",
    "ax2.hist(train_wo_outliers.Popularity)\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats.loc['Likes']['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=train[['Views', 'Comments', 'Popularity', 'Followers', 'Likes', 'Time_epoch']].corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Views', 'Comments', 'Popularity', 'Followers', 'Likes', 'Time_epoch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train[['Views', 'Comments', 'Popularity', 'Followers', 'Likes', 'Time_epoch']], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, cmap='PuOr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Likes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Genre.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Views.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Song_Name.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(by=['Name','Views','Timestamp'])\n",
    "train.sort_values(by=['Time_epoch', 'Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Timestamp.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(by='Views')['Views']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
